{"nbformat":4,"nbformat_minor":0,"metadata":{"accelerator":"GPU","colab":{"name":"lstm_den_ae_2018.ipynb","provenance":[{"file_id":"1KpBeHwf6NshK6qXxAF-MO3FelmWns_qx","timestamp":1627275074871}],"collapsed_sections":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","metadata":{"id":"BAgdx8jze5CW"},"source":["## Mounting drive"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"9MLNSecLW45X","executionInfo":{"status":"ok","timestamp":1628753650663,"user_tz":420,"elapsed":30824,"user":{"displayName":"Amadou Tall","photoUrl":"","userId":"06820629351691459518"}},"outputId":"aac4d3b7-cb3d-43a2-93e3-251178190029"},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"PGmnOsEUfGQq"},"source":["## 1. Loading data"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":17,"output_embedded_package_id":"1qEtwgpDkTKmk7Zx1PKf1i--jbD0LwT-1"},"id":"Pr8yAx7NXVpS","executionInfo":{"status":"ok","timestamp":1628753663734,"user_tz":420,"elapsed":9005,"user":{"displayName":"Amadou Tall","photoUrl":"","userId":"06820629351691459518"}},"outputId":"20d33287-75bc-4e68-dcfc-68c991019b54"},"source":["import os\n","os.environ[\"CUDA_DEVICE_ORDER\"] = 'PCI_BUS_ID'\n","os.environ['CUDA_VISIBLE_DEVICES']= '0'\n","import numpy as np\n","import pickle\n","import tensorflow as tf\n","import plotly.graph_objs as go\n","import matplotlib.pyplot as plt\n","from plotly.offline import init_notebook_mode, iplot\n","import time\n","import seaborn as sn\n","import pandas as pd\n","import h5py\n","init_notebook_mode()"],"execution_count":2,"outputs":[{"output_type":"display_data","data":{"text/plain":"Output hidden; open in https://colab.research.google.com to view."},"metadata":{}}]},{"cell_type":"code","metadata":{"id":"qFsgAogGty9g","executionInfo":{"status":"ok","timestamp":1628753669959,"user_tz":420,"elapsed":427,"user":{"displayName":"Amadou Tall","photoUrl":"","userId":"06820629351691459518"}}},"source":["# parameters\n","data_path = '/content/drive/MyDrive/Colab Notebooks/Data/'\n","file_name = 'RML2016.10a_dict.pkl'"],"execution_count":3,"outputs":[]},{"cell_type":"code","metadata":{"id":"h4pmd4xm2lqR","executionInfo":{"status":"ok","timestamp":1628753673814,"user_tz":420,"elapsed":320,"user":{"displayName":"Amadou Tall","photoUrl":"","userId":"06820629351691459518"}}},"source":["def get_amp_phase(data):\n","    X_train_cmplx = data[:, 0, :] + 1j * data[:, 1, :]\n","    X_train_amp = np.abs(X_train_cmplx)\n","    X_train_ang = np.arctan2(data[:, 1, :], data[:, 0, :]) / np.pi\n","    X_train_amp = np.reshape(X_train_amp, (-1, 1, signal_len))\n","    X_train_ang = np.reshape(X_train_ang, (-1, 1, signal_len))\n","    X_train = np.concatenate((X_train_amp, X_train_ang), axis = 1) \n","    X_train = np.transpose(np.array(X_train), (0, 2, 1))\n","    for i in range(X_train.shape[0]):\n","        X_train[i, :, 0] = X_train[i, :, 0] / np.linalg.norm(X_train[i, :, 0], 2)\n","    \n","    return X_train"],"execution_count":4,"outputs":[]},{"cell_type":"code","metadata":{"id":"YDd4gGEt29It","executionInfo":{"status":"ok","timestamp":1628754120826,"user_tz":420,"elapsed":429,"user":{"displayName":"Amadou Tall","photoUrl":"","userId":"06820629351691459518"}}},"source":["def set_up_data(data_path, file_name):\n","    f = h5py.File(data_path + file_name, 'r')\n","    data = f['X'][()]\n","    label = f['Y'][()]\n","    SNR = f['Z'][()]\n","    \n","    classes = ['32PSK',\n","             '16APSK',\n","             '32QAM',\n","             'FM',\n","             'GMSK',\n","             '32APSK',\n","             'OQPSK',\n","             '8ASK',\n","             'BPSK',\n","             '8PSK',\n","             'AM-SSB-SC',\n","             '4ASK',\n","             '16PSK',\n","             '64APSK',\n","             '128QAM',\n","             '128APSK',\n","             'AM-DSB-SC',\n","             'AM-SSB-WC',\n","             '64QAM',\n","             'QPSK',\n","             '256QAM',\n","             'AM-DSB-WC',\n","             'OOK',\n","             '16QAM']\n","    \n","    dic = {}\n","    for i in np.unique(label):\n","        dic[int(i)] = classes[int(i)]\n","\n","    modulation_index = {'FM': 0, 'GMSK': 1, 'OQPSK': 2, 'BPSK': 3, '8PSK': 4, 'AM-SSB-SC': 5, '4ASK': 6, 'AM-DSB-SC': 7, 'QPSK': 8, 'OOK': 9, '16QAM': 10}\n","\n","    label = np.reshape(label, (-1, 1))\n","    for i in range(label.shape[0]):\n","        label[i, 0] = modulation_index[dic[label[i, 0]]]\n","\n","    label = np.concatenate((label, SNR), axis = 1)\n","    \n","    index = list(range(data.shape[0]))\n","    np.random.seed(2019)\n","    np.random.shuffle(index)\n","\n","    train_proportion = 0.5\n","    validation_proportion = 0.25\n","    test_proportion = 0.25\n","\n","    X_train = data[index[:int(data.shape[0] * train_proportion)], :, :]\n","    Y_train = label[index[:int(data.shape[0] * train_proportion)], :]\n","    X_validation = data[index[int(data.shape[0] * train_proportion) : int(data.shape[0] * (train_proportion + validation_proportion))], :, :]\n","    Y_validation = label[index[int(data.shape[0] * train_proportion) : int(data.shape[0] * (train_proportion + validation_proportion))], :]\n","    X_test = data[index[int(data.shape[0] * (train_proportion + validation_proportion)):], :, :]\n","    Y_test = label[index[int(data.shape[0] * (train_proportion + validation_proportion)):], :]\n","    \n","    return X_train, Y_train, X_validation, Y_validation, X_test, Y_test, modulation_index"],"execution_count":11,"outputs":[]},{"cell_type":"code","metadata":{"id":"Pr64LNaT3Myr","executionInfo":{"status":"ok","timestamp":1628754020629,"user_tz":420,"elapsed":344,"user":{"displayName":"Amadou Tall","photoUrl":"","userId":"06820629351691459518"}}},"source":["def zero_mask(X_train, p):\n","    num = int(X_train.shape[1] * p)\n","    res = X_train.copy()\n","    index = np.array([[i for i in range(X_train.shape[1])] for _ in range(X_train.shape[0])])\n","    for i in range(index.shape[0]):\n","        np.random.shuffle(index[i, :])\n","    \n","    for i in range(res.shape[0]):\n","        res[i, index[i, :num], :] = 0\n","        \n","    return res\n","\n"],"execution_count":9,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":368},"id":"ARc_axrj3ZS2","executionInfo":{"status":"error","timestamp":1628754025489,"user_tz":420,"elapsed":406,"user":{"displayName":"Amadou Tall","photoUrl":"","userId":"06820629351691459518"}},"outputId":"5593733b-4137-49e9-de1c-98b73b8d3b34"},"source":["# set up data\n","X_train, Y_train, X_validation, Y_validation, X_test, Y_test, modulation_index = set_up_data(data_path, file_name)\n","\n","X_train = np.moveaxis(X_train, 1, 2)\n","X_validation = np.moveaxis(X_validation, 1, 2)\n","X_test = np.moveaxis(X_test, 1, 2)\n","\n","X_train = get_amp_phase(X_train)\n","X_validation = get_amp_phase(X_validation)\n","X_test = get_amp_phase(X_test)\n","\n","Y_train = Y_train.astype(int)\n","Y_validation = Y_validation.astype(int)\n","Y_test = Y_test.astype(int)\n","\n","encoder_inputs = tf.keras.Input(shape = (X_train.shape[1], X_train.shape[2]),\n","                                name = 'encoder_inputs')\n","\n","encoder_1, state_h_1, state_c_1 = tf.keras.layers.CuDNNLSTM(units = 32,\n","                                    return_sequences = True,\n","                                    return_state = True,\n","                                    name = 'encoder_1')(encoder_inputs)\n","\n","drop_prob = 0.2\n","drop_1 = tf.keras.layers.Dropout(drop_prob, name = 'drop_1')(encoder_1)\n","\n","encoder_2, state_h_2, state_c_2 = tf.keras.layers.CuDNNLSTM(units = 32,\n","                                    return_state = True,\n","                                    return_sequences = True,                \n","                                    name = 'encoder_2')(drop_1)\n","\n","decoder = tf.keras.layers.TimeDistributed(tf.keras.layers.Dense(2),\n","                                          name = 'decoder')(encoder_2)"],"execution_count":10,"outputs":[{"output_type":"error","ename":"NameError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-10-03835e3b815c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# set up data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_validation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_validation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodulation_index\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mset_up_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfile_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mX_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmoveaxis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mX_validation\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmoveaxis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_validation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-8-4fd489f296cd>\u001b[0m in \u001b[0;36mset_up_data\u001b[0;34m(data_path, file_name)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mset_up_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfile_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpkl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_path\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mfile_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'r'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'X'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mlabel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Y'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mSNR\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Z'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'pkl' is not defined"]}]},{"cell_type":"code","metadata":{"id":"GHIldZqOXkuu"},"source":["# 3 Dense layers for classification with bn\n","clf_dropout = 0.2\n","\n","clf_dense_1 = tf.keras.layers.Dense(units = 32,\n","                                    activation = tf.nn.relu,\n","                                    name = 'clf_dense_1')(state_h_2)\n","\n","bn_1 = tf.keras.layers.BatchNormalization(name = 'bn_1')(clf_dense_1)\n","\n","clf_drop_1 = tf.keras.layers.Dropout(clf_dropout, name = 'clf_drop_1')(bn_1)\n","\n","clf_dense_2 = tf.keras.layers.Dense(units = 16,\n","                                    activation = tf.nn.relu,\n","                                    name = 'clf_dense_2')(clf_drop_1)\n","\n","bn_2 = tf.keras.layers.BatchNormalization(name = 'bn_2')(clf_dense_2)\n","\n","clf_drop_2 = tf.keras.layers.Dropout(clf_dropout, name = 'clf_drop_2')(bn_2)\n","\n","clf_dense_3 = tf.keras.layers.Dense(units = modulation_num,\n","                                    name = 'clf_dense_3')(clf_drop_2)\n","\n","softmax = tf.keras.layers.Softmax(name = 'softmax')(clf_dense_3)\n","\n","model = tf.keras.Model(inputs = encoder_inputs, outputs = [decoder, softmax])\n","model.summary()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"8X4x4T3VMlLf"},"source":["learning_rate = 10 ** -3\n","lam = 0.1\n","\n","model.compile(loss = ['mean_squared_error', 'categorical_crossentropy'],\n","              loss_weights = [1 - lam, lam],\n","              metrics=['accuracy'],\n","              optimizer = tf.keras.optimizers.Adam(lr = learning_rate))\n","\n","best = 0\n","train_acc = []\n","val_acc = []\n","\n","\n","for ite in range(150):\n","    X_train_masked = zero_mask(X_train, 0.1)\n","    print(ite)\n","    history = model.fit(x = X_train,\n","                        y = [X_train, tf.keras.utils.to_categorical(Y_train[:, 0])],\n","                        validation_data = (X_validation, [X_validation, tf.keras.utils.to_categorical(Y_validation[:, 0])]),\n","                        batch_size = 128,\n","                        epochs = 1)\n","    \n","    train_acc.append(history.history['softmax_acc'][0])\n","    val_acc.append(history.history['val_softmax_acc'][0])\n","\n","    if history.history['val_softmax_acc'][0] > best:\n","        best = history.history['val_softmax_acc'][0]\n","        model.save('DAELSTM.h5')\n","\n","    with open('val_result.txt', 'a') as f:\n","        f.write(str(history.history['val_softmax_acc'][0] * 100) + '\\n')\n","        \n","\n","clf = tf.keras.models.load_model('DAELSTM.h5')\n","\n","res = clf.predict(X_test)[1]\n","res = np.argmax(res, axis = 1)\n","test_accuracy = {}\n","for i in range(X_test.shape[0]):\n","    if Y_test[i, 1] not in test_accuracy:\n","        if Y_test[i, 0] == res[i]:\n","            test_accuracy[Y_test[i, 1]] = [1, 1]\n","        else:\n","            test_accuracy[Y_test[i, 1]] = [0, 1]\n","    else:\n","        if Y_test[i, 0] == res[i]:\n","            test_accuracy[Y_test[i, 1]][0] += 1\n","            test_accuracy[Y_test[i, 1]][1] += 1\n","        else:\n","            test_accuracy[Y_test[i, 1]][1] += 1\n","\n","nomi = 0\n","deno = 0\n","for snr in test_accuracy:\n","    nomi += test_accuracy[snr][0]\n","    deno += test_accuracy[snr][1]\n","\n","best = nomi / deno\n","\n","with open('result.txt', 'a') as f:\n","    for item in [test_accuracy[i][0] / test_accuracy[i][1] for i in np.sort(list(test_accuracy))]:\n","        f.write(str(item * 100) + '\\n')\n","        \n","    f.write(str(best * 100) + '\\n')\n","    f.write('\\n')"],"execution_count":null,"outputs":[]}]}