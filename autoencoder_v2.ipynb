{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"autoencoder_v2.ipynb","provenance":[{"file_id":"1EVfo4VVzJ-nyyq_YJRCfn3sBxzc5sHGH","timestamp":1626816531430}],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"BAgdx8jze5CW"},"source":["## Mounting drive"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"9MLNSecLW45X","executionInfo":{"status":"ok","timestamp":1627233838113,"user_tz":420,"elapsed":159,"user":{"displayName":"Amadou Tall","photoUrl":"","userId":"06820629351691459518"}},"outputId":"e1c24edf-9480-4222-8d5a-883d30748b83"},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"PGmnOsEUfGQq"},"source":["## 1. Loading data"]},{"cell_type":"code","metadata":{"id":"Pr8yAx7NXVpS"},"source":["import pickle\n","import numpy as np\n","import random"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"QawPybbNXjDm"},"source":["# open a file, where you stored the pickled data\n","with open('/content/drive/MyDrive/Colab Notebooks/Data/gnu_data.pkl', 'rb') as file:\n","\n","    # dump information to that file\n","    Xd = pickle.load(file,encoding='latin1')\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"GHIldZqOXkuu"},"source":["Xd['X']\n","Xd['lbl']\n","\n","X     = []\n","modul = []\n","snr   = []\n","\n","for i in range(len(Xd['X'])):\n","    x_ = Xd['X'][i]\n","    X.append(np.reshape(x_,(-1)))\n","    \n","    lbl = Xd['lbl'][i]\n","    modul.append(lbl[0])\n","    snr.append(int(lbl[1]))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"hCWTYfuMfJXg"},"source":["### 1.1. Train/Test Split"]},{"cell_type":"code","metadata":{"id":"__Y7wHsSYJjk"},"source":["train_test_split = 0.8\n","\n","random.seed(100)\n","random.shuffle(X)\n","\n","random.seed(100)\n","random.shuffle(modul)\n","\n","random.seed(100)\n","random.shuffle(snr)\n","\n","\n","X_train = np.array(X[:int(train_test_split*len(X))])\n","X_test  = np.array(X[int(train_test_split*len(X)):])\n","\n","modul_train = modul[:int(train_test_split*len(X))]\n","modul_test  = modul[int(train_test_split*len(X)):]\n","\n","snr_train = snr[:int(train_test_split*len(X))]\n","snr_test  = snr[int(train_test_split*len(X)):]"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"_u3G7DydfpbV"},"source":["### 1.2. Generating One-hot encoded"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"k6xvyHtGfpA6","executionInfo":{"status":"ok","timestamp":1627233844873,"user_tz":420,"elapsed":372,"user":{"displayName":"Amadou Tall","photoUrl":"","userId":"06820629351691459518"}},"outputId":"439e0585-7dc2-42f6-fc94-54a7f6eb913d"},"source":["mods = list(set(modul_train))\n","print(len(mods))\n","\n","def to_onehot(yy):\n","    yy1 = np.zeros([1, len(mods)])\n","    yy1[0,mods.index(yy)] = 1\n","    return yy1\n","\n","Y_train = np.zeros([len(modul_train),len(mods)])\n","Y_test = np.zeros([len(modul_test),len(mods)])\n","\n","for i in range(len(modul_train)):\n","  Y_train[i,:] = to_onehot(modul_train[i])\n","\n","for i in range(len(modul_test)):\n","  Y_test[i,:] = to_onehot(modul_test[i]) "],"execution_count":null,"outputs":[{"output_type":"stream","text":["11\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"TGQ95vjMfPfl"},"source":["## 2. Train Deep Neural Networks"]},{"cell_type":"markdown","metadata":{"id":"-f6J_-kufXFO"},"source":["### 2.1. Train Auto-Encoder (AE)"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":613},"id":"A6ou-bCcYKGC","executionInfo":{"status":"ok","timestamp":1627234345404,"user_tz":420,"elapsed":167,"user":{"displayName":"Amadou Tall","photoUrl":"","userId":"06820629351691459518"}},"outputId":"740d127c-5ea7-4c41-c09c-b975235a32a8"},"source":["import keras\n","\n","# This is the size of our encoded representations\n","encoding_dim = 64  # 32 floats -> compression of factor 24.5, assuming the input is 784 floats\n","data_dim     = (128,2,1,) #X[0].shape[0]\n","\n","input_data = keras.Input(shape=(data_dim))\n","\n","# Encoder\n","x = keras.layers.Conv2D(8, (3, 3), activation=\"relu\", padding=\"same\")(input_data)\n","x = keras.layers.MaxPooling2D((2, 2), padding=\"same\")(x)\n","x = keras.layers.Conv2D(32, (3, 3), activation=\"relu\", padding=\"same\")(x)\n","x = keras.layers.MaxPooling2D((2, 2), padding=\"same\")(x)\n","\n","# Decoder\n","x = keras.layers.Conv2DTranspose(32, (3, 3), strides=2, activation=\"relu\", padding=\"same\")(x)\n","x = keras.layers.Conv2DTranspose(32, (3, 3), strides=2, activation=\"relu\", padding=\"same\")(x)\n","x = keras.layers.Conv2D(1, (3, 3), activation=\"sigmoid\", padding=\"same\")(x)\n","\n","# Autoencoder\n","autoencoder = keras.Model(input_data, x)\n","autoencoder.compile(optimizer=\"adam\", loss=\"binary_crossentropy\")\n","autoencoder.summary()\n","\n","'''# This is our input image\n","input_data     = keras.Input(shape=(data_dim,))\n","layer1_encoder = keras.layers.Dense(200, activation='tanh')(input_data)\n","# layer1_encoder = keras.layers.BatchNormalization()(layer1_encoder)\n","# layer1_encoder = keras.layers.Dropout(0.3)(layer1_encoder)\n","layer2_encoder = keras.layers.Dense(200, activation='tanh')(layer1_encoder)\n","# layer2_encoder = keras.layers.BatchNormalization()(layer2_encoder)\n","# layer2_encoder = keras.layers.Dropout(0.3)(layer2_encoder)\n","encoded        = keras.layers.Dense(encoding_dim, activation='tanh',name='encoding')(layer2_encoder)\n","layer1_decoder = keras.layers.Dense(200, activation='tanh')(encoded)\n","# layer1_decoder = keras.layers.BatchNormalization()(layer1_decoder)\n","# layer1_decoder = keras.layers.Dropout(0.3)(layer1_decoder)\n","layer2_decoder = keras.layers.Dense(200, activation='tanh')(layer1_decoder)\n","# layer2_decoder = keras.layers.BatchNormalization()(layer2_decoder)\n","# layer2_decoder = keras.layers.Dropout(0.3)(layer2_decoder)\n","decoded        = keras.layers.Dense(data_dim, activation='tanh')(layer2_decoder)\n","\n","# This model maps an input to its reconstruction\n","autoencoder = keras.Model(input_data, decoded)\n","autoencoder.compile(loss='mse', optimizer='adam')\n","autoencoder.summary()'''"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Model: \"model_3\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","input_4 (InputLayer)         [(None, 128, 2, 1)]       0         \n","_________________________________________________________________\n","conv2d_9 (Conv2D)            (None, 128, 2, 8)         80        \n","_________________________________________________________________\n","max_pooling2d_6 (MaxPooling2 (None, 64, 1, 8)          0         \n","_________________________________________________________________\n","conv2d_10 (Conv2D)           (None, 64, 1, 32)         2336      \n","_________________________________________________________________\n","max_pooling2d_7 (MaxPooling2 (None, 32, 1, 32)         0         \n","_________________________________________________________________\n","conv2d_transpose_6 (Conv2DTr (None, 64, 2, 32)         9248      \n","_________________________________________________________________\n","conv2d_transpose_7 (Conv2DTr (None, 128, 4, 32)        9248      \n","_________________________________________________________________\n","conv2d_11 (Conv2D)           (None, 128, 4, 1)         289       \n","=================================================================\n","Total params: 21,201\n","Trainable params: 21,201\n","Non-trainable params: 0\n","_________________________________________________________________\n"],"name":"stdout"},{"output_type":"execute_result","data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["\"# This is our input image\\ninput_data     = keras.Input(shape=(data_dim,))\\nlayer1_encoder = keras.layers.Dense(200, activation='tanh')(input_data)\\n# layer1_encoder = keras.layers.BatchNormalization()(layer1_encoder)\\n# layer1_encoder = keras.layers.Dropout(0.3)(layer1_encoder)\\nlayer2_encoder = keras.layers.Dense(200, activation='tanh')(layer1_encoder)\\n# layer2_encoder = keras.layers.BatchNormalization()(layer2_encoder)\\n# layer2_encoder = keras.layers.Dropout(0.3)(layer2_encoder)\\nencoded        = keras.layers.Dense(encoding_dim, activation='tanh',name='encoding')(layer2_encoder)\\nlayer1_decoder = keras.layers.Dense(200, activation='tanh')(encoded)\\n# layer1_decoder = keras.layers.BatchNormalization()(layer1_decoder)\\n# layer1_decoder = keras.layers.Dropout(0.3)(layer1_decoder)\\nlayer2_decoder = keras.layers.Dense(200, activation='tanh')(layer1_decoder)\\n# layer2_decoder = keras.layers.BatchNormalization()(layer2_decoder)\\n# layer2_decoder = keras.layers.Dropout(0.3)(layer2_decoder)\\ndecoded        = keras.layers.Dense(data_dim, activation='tanh')(layer2_decoder)\\n\\n# This model maps an input to its reconstruction\\nautoencoder = keras.Model(input_data, decoded)\\nautoencoder.compile(loss='mse', optimizer='adam')\\nautoencoder.summary()\""]},"metadata":{"tags":[]},"execution_count":13}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":698},"id":"CVa0OBLfYevQ","executionInfo":{"status":"error","timestamp":1627234354651,"user_tz":420,"elapsed":219,"user":{"displayName":"Amadou Tall","photoUrl":"","userId":"06820629351691459518"}},"outputId":"ea257db8-5737-4db2-f59c-c18c405bed19"},"source":["# Set up some params \n","nb_epoch = 100     # number of epochs to train on\n","batch_size = 32  # training batch size\n","\n","filepath = '/content/drive/My Drive/amadou/AE.h5'\n","autoencoder.fit(X_train,\n","    X_train,\n","    batch_size=batch_size,\n","    epochs=nb_epoch,\n","    verbose=1,\n","    validation_data=(X_test,X_test),\n","    callbacks = [\n","        keras.callbacks.ModelCheckpoint(filepath, monitor='val_loss', verbose=0, save_best_only=True, mode='auto'),\n","        keras.callbacks.EarlyStopping(monitor='val_loss', patience=5, verbose=0, mode='auto')]\n","    )\n","# we re-load the best weights once training is finished\n","autoencoder.load_weights(filepath)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Epoch 1/100\n"],"name":"stdout"},{"output_type":"error","ename":"ValueError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","\u001b[0;32m<ipython-input-14-8531beb68433>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m     callbacks = [\n\u001b[1;32m     13\u001b[0m         \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mModelCheckpoint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmonitor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'val_loss'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msave_best_only\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'auto'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m         keras.callbacks.EarlyStopping(monitor='val_loss', patience=5, verbose=0, mode='auto')]\n\u001b[0m\u001b[1;32m     15\u001b[0m     )\n\u001b[1;32m     16\u001b[0m \u001b[0;31m# we re-load the best weights once training is finished\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1156\u001b[0m                 _r=1):\n\u001b[1;32m   1157\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1158\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1159\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1160\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    887\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    891\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    931\u001b[0m       \u001b[0;31m# This is the first call of __call__, so we have to initialize.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    932\u001b[0m       \u001b[0minitializers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 933\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_initialize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0madd_initializers_to\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitializers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    934\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    935\u001b[0m       \u001b[0;31m# At this point we know that the initialization is complete (or less\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_initialize\u001b[0;34m(self, args, kwds, add_initializers_to)\u001b[0m\n\u001b[1;32m    762\u001b[0m     self._concrete_stateful_fn = (\n\u001b[1;32m    763\u001b[0m         self._stateful_fn._get_concrete_function_internal_garbage_collected(  # pylint: disable=protected-access\n\u001b[0;32m--> 764\u001b[0;31m             *args, **kwds))\n\u001b[0m\u001b[1;32m    765\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    766\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0minvalid_creator_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0munused_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0munused_kwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_get_concrete_function_internal_garbage_collected\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   3048\u001b[0m       \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3049\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3050\u001b[0;31m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3051\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3052\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_maybe_define_function\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   3442\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3443\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmissed\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcall_context_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3444\u001b[0;31m           \u001b[0mgraph_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_graph_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3445\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprimary\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcache_key\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3446\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_create_graph_function\u001b[0;34m(self, args, kwargs, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m   3287\u001b[0m             \u001b[0marg_names\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0marg_names\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3288\u001b[0m             \u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3289\u001b[0;31m             capture_by_value=self._capture_by_value),\n\u001b[0m\u001b[1;32m   3290\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_attributes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3291\u001b[0m         \u001b[0mfunction_spec\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_spec\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mfunc_graph_from_py_func\u001b[0;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m    997\u001b[0m         \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moriginal_func\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_decorator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munwrap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpython_func\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    998\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 999\u001b[0;31m       \u001b[0mfunc_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpython_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mfunc_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfunc_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1000\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1001\u001b[0m       \u001b[0;31m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36mwrapped_fn\u001b[0;34m(*args, **kwds)\u001b[0m\n\u001b[1;32m    670\u001b[0m         \u001b[0;31m# the function a weak reference to itself to avoid a reference cycle.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    671\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcompile_with_xla\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 672\u001b[0;31m           \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mweak_wrapped_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__wrapped__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    673\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    674\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    984\u001b[0m           \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint:disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    985\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"ag_error_metadata\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 986\u001b[0;31m               \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mag_error_metadata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    987\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    988\u001b[0m               \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mValueError\u001b[0m: in user code:\n\n    /usr/local/lib/python3.7/dist-packages/keras/engine/training.py:830 train_function  *\n        return step_function(self, iterator)\n    /usr/local/lib/python3.7/dist-packages/keras/engine/training.py:813 run_step  *\n        outputs = model.train_step(data)\n    /usr/local/lib/python3.7/dist-packages/keras/engine/training.py:770 train_step  *\n        y_pred = self(x, training=True)\n    /usr/local/lib/python3.7/dist-packages/keras/engine/base_layer.py:989 __call__  *\n        input_spec.assert_input_compatibility(self.input_spec, inputs, self.name)\n    /usr/local/lib/python3.7/dist-packages/keras/engine/input_spec.py:264 assert_input_compatibility  *\n        raise ValueError('Input ' + str(input_index) +\n\n    ValueError: Input 0 is incompatible with layer model_3: expected shape=(None, 128, 2, 1), found shape=(32, 256)\n"]}]},{"cell_type":"markdown","metadata":{"id":"GtskO1KEfhpi"},"source":["### 2.2. Define Encoder model (trained)"]},{"cell_type":"code","metadata":{"id":"ve5JXewzhh-2"},"source":["encoder_model = keras.Model(inputs=autoencoder.input,\n","                                 outputs=autoencoder.get_layer('encoding').output)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"gHWRIRjygBL2"},"source":["### 2.3. Calculate Encoded data (train & test) using trained Encoder Model"]},{"cell_type":"code","metadata":{"id":"7WsI-sTJjvKg"},"source":["encoded_train = encoder_model.predict(X_train, verbose=1)\n","encoded_test  = encoder_model.predict(X_test, verbose=1)\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Iea9uP6WgPg7"},"source":["### 2.4. Train MLP Classifier"]},{"cell_type":"code","metadata":{"id":"O-alHGxUkoPQ"},"source":["model = keras.models.Sequential()\n","model.add(keras.layers.Dense(100, activation='relu', name=\"dense1\", input_shape=(encoding_dim,)))\n","model.add(keras.layers.Dropout(0.1))\n","model.add(keras.layers.Dense(100, activation='relu', name=\"dense2\"))\n","model.add(keras.layers.Dropout(0.1))\n","model.add(keras.layers.Dense( 11, name=\"output\" ))\n","model.add(keras.layers.Activation('softmax'))\n","model.compile(loss='categorical_crossentropy', optimizer='adam',metrics='acc')\n","model.summary()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"A5DvLB0jnQkM"},"source":["filepath = '/content/drive/My Drive/amadou/AE_MLP.h5'\n","\n","model.fit(encoded_train,\n","    Y_train,\n","    batch_size=batch_size,\n","    epochs=nb_epoch,\n","    verbose=1,\n","    validation_data=(encoded_test,Y_test),\n","    callbacks = [\n","        keras.callbacks.ModelCheckpoint(filepath, monitor='val_loss', verbose=0, save_best_only=True, mode='auto'),\n","        keras.callbacks.EarlyStopping(monitor='val_loss', patience=5, verbose=0, mode='auto')]\n","    )\n","# we re-load the best weights once training is finished\n","model.load_weights(filepath)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"E_tuOktugWeZ"},"source":["## 3. Evaluating the trained classifier"]},{"cell_type":"code","metadata":{"id":"R8mMZwWLLU-6"},"source":["snrs= list(set(snr))\n","snrs.sort()\n","\n","import matplotlib.pyplot as plt\n","def plot_confusion_matrix(cm, title='Confusion matrix', cmap=plt.cm.Blues, labels=[]):\n","    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n","    plt.title(title)\n","    plt.colorbar()\n","    tick_marks = np.arange(len(labels))\n","    plt.xticks(tick_marks, labels, rotation=45)\n","    plt.yticks(tick_marks, labels)\n","    plt.tight_layout()\n","    plt.ylabel('True label')\n","    plt.xlabel('Predicted label')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"NoBOcX-EoJTT"},"source":["\n","# Plot confusion matrix\n","acc = {}\n","for snr_value in snrs:\n","\n","    # extract classes @ SNR\n","    test_X_i = X_test[np.where(np.array(snr_test)==snr_value)]\n","    test_Y_i = Y_test[np.where(np.array(snr_test)==snr_value)]    \n","\n","    # estimate classes\n","    test_encoded = encoder_model.predict(test_X_i)\n","    test_Y_i_hat = model.predict(test_encoded)\n","    conf = np.zeros([len(mods),len(mods)])\n","    confnorm = np.zeros([len(mods),len(mods)])\n","    for i in range(0,test_X_i.shape[0]):\n","        j = list(test_Y_i[i,:]).index(1)\n","        k = int(np.argmax(test_Y_i_hat[i,:]))\n","        conf[j,k] = conf[j,k] + 1\n","    for i in range(0,len(mods)):\n","        confnorm[i,:] = conf[i,:] / np.sum(conf[i,:])\n","    plt.figure()\n","    plot_confusion_matrix(confnorm, labels=mods, title=\"AE Confusion Matrix (SNR=%d)\"%(int(snr_value)))\n","    \n","    cor = np.sum(np.diag(conf))\n","    ncor = np.sum(conf) - cor\n","    print (\"Overall Accuracy: \", cor / (cor+ncor))\n","    acc[snr_value] = 1.0*cor/(cor+ncor)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"VPOhXAKaJ8yk"},"source":["acc_ = [acc[snr_value] for snr_value in snrs]\n","\n","# Plot accuracy curve\n","plt.plot(snrs, acc_)\n","plt.xlabel(\"Signal to Noise Ratio\")\n","plt.ylabel(\"Classification Accuracy\")\n","plt.title(\"AE Classification Accuracy on RadioML 2016.10 Alpha\")"],"execution_count":null,"outputs":[]}]}