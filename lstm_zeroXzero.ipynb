{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"lstm_zeroXzero.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyNx7jJ5MWrYUjgyUbHldPwj"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"BRRIuI__h0jQ","executionInfo":{"status":"ok","timestamp":1630101971712,"user_tz":420,"elapsed":27548,"user":{"displayName":"Amadou Tall","photoUrl":"","userId":"06820629351691459518"}},"outputId":"47439d1f-fcfc-4845-a5c6-748f2baf1295"},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":5,"outputs":[{"output_type":"stream","text":["Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"QXX70r7sVizy","executionInfo":{"status":"ok","timestamp":1630101985014,"user_tz":420,"elapsed":138,"user":{"displayName":"Amadou Tall","photoUrl":"","userId":"06820629351691459518"}}},"source":["import numpy as np\n","#import tflearn\n","import tensorflow as tf\n","from sklearn.metrics import confusion_matrix\n","import matplotlib.pyplot as plt\n","import sys\n","import operator\n","import pickle\n","from numpy import linalg as la "],"execution_count":6,"outputs":[]},{"cell_type":"code","metadata":{"id":"myIUYrZUoaUp","executionInfo":{"status":"ok","timestamp":1630101988472,"user_tz":420,"elapsed":147,"user":{"displayName":"Amadou Tall","photoUrl":"","userId":"06820629351691459518"}}},"source":["# parameters\n","data_path = '/content/drive/MyDrive/Colab Notebooks/Data/'\n","file_name = 'RML2016.10a_dict.pkl'"],"execution_count":7,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":368},"id":"S42DAot8Vpp4","executionInfo":{"status":"error","timestamp":1630101992124,"user_tz":420,"elapsed":1480,"user":{"displayName":"Amadou Tall","photoUrl":"","userId":"06820629351691459518"}},"outputId":"3fb6d367-bd52-404f-f8b6-d2d51776e127"},"source":["maxlen = 128 \n","snrs=\"\"\n","mods=\"\"\n","test_idx=\"\"\n","lbl =\"\"\n","def gendata(fp, nsamples):\n","    global snrs, mods, test_idx, lbl\n","    Xd = pickle.load(open(data_path + file_name,'rb'))\n","    snrs,mods = map(lambda j: sorted(list(set(map(lambda x: x[j], Xd.keys())))), [1,0])\n","    X = []  \n","    lbl = []\n","    print(mods, snrs)\n","    for mod in mods:\n","        for snr in snrs:\n","            X.append(Xd[(mod,snr)])\n","            for i in range(Xd[(mod,snr)].shape[0]):\n","                lbl.append((mod,snr))\n","    X = np.vstack(X)\n","    \n","    np.random.seed(2016)\n","    n_examples = X.shape[0]\n","    n_train = int(n_examples * 0.5)\n","    train_idx = np.random.choice(range(0,n_examples), size=n_train, replace=False)\n","    test_idx = list(set(range(0,n_examples))-set(train_idx))\n","    X_train = X[train_idx]\n","    X_test =  X[test_idx]\n","    def to_onehot(yy):\n","        yy1 = np.zeros([len(yy), max(yy)+1])\n","        yy1[np.arange(len(yy)),yy] = 1\n","        return yy1\n","    Y_train = to_onehot(map(lambda x: mods.index(lbl[x][0]), train_idx))\n","    Y_test = to_onehot(map(lambda x: mods.index(lbl[x][0]), test_idx))\n","   \n","    return (X_train,X_test,Y_train,Y_test)\n","\n","\n","def norm_pad_zeros(X_train,nsamples):\n","    print(\"Pad:\", X_train.shape)\n","    for i in range(X_train.shape[0]):\n","        X_train[i,:,0] = X_train[i,:,0]/la.norm(X_train[i,:,0],2)\n","    return X_train\n","\n","\n","def to_amp_phase(X_train,X_test,nsamples):\n","    X_train_cmplx = X_train[:,0,:] + 1j* X_train[:,1,:]\n","    X_test_cmplx = X_test[:,0,:] + 1j* X_test[:,1,:]\n","    \n","    X_train_amp = np.abs(X_train_cmplx)\n","    X_train_ang = np.arctan2(X_train[:,1,:],X_train[:,0,:])/np.pi\n","    \n","    \n","    X_train_amp = np.reshape(X_train_amp,(-1,1,nsamples))\n","    X_train_ang = np.reshape(X_train_ang,(-1,1,nsamples))\n","    \n","    X_train = np.concatenate((X_train_amp,X_train_ang), axis=1) \n","    X_train = np.transpose(np.array(X_train),(0,2,1))\n","    \n","    X_test_amp = np.abs(X_test_cmplx)\n","    X_test_ang = np.arctan2(X_test[:,1,:],X_test[:,0,:])/np.pi\n","    \n","    \n","    X_test_amp = np.reshape(X_test_amp,(-1,1,nsamples))\n","    X_test_ang = np.reshape(X_test_ang,(-1,1,nsamples))\n","    \n","    X_test = np.concatenate((X_test_amp,X_test_ang), axis=1) \n","    X_test = np.transpose(np.array(X_test),(0,2,1))\n","    return (X_train, X_test)\n","\n","\n","xtrain1,xtest1,ytrain1,ytest1 = gendata('/content/drive/MyDrive/Colab Notebooks/Data/RML2016.10a_dict.pkl',128)\n","\n","\n","xtrain1,xtest1 = to_amp_phase(xtrain1,xtest1,128)\n","\n","xtrain1 = xtrain1[:,:maxlen,:]\n","xtest1 = xtest1[:,:maxlen,:]\n","\n","xtrain1 = norm_pad_zeros(xtrain1,maxlen)\n","xtest1 = norm_pad_zeros(xtest1,maxlen)\n","\n","\n","X_train = xtrain1\n","X_test = xtest1\n","\n","Y_train = ytrain1\n","Y_test = ytest1\n","\n","print(\"--\"*50)\n","print(\"Training data:\",X_train.shape)\n","print(\"Training labels:\",Y_train.shape)\n","print(\"Testing data\",X_test.shape)\n","print(\"Testing labels\",Y_test.shape)\n","print(\"--\"*50)\n","\n","def getFontColor(value):\n","    if np.isnan(value):\n","        return \"black\"\n","    elif value < 0.2:\n","        return \"black\"\n","    else:\n","        return \"white\"\n","\n","def getConfusionMatrixPlot(true_labels, predicted_labels):\n","    # Compute confusion matrix\n","    cm = confusion_matrix(true_labels, predicted_labels)\n","    cm_norm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n","    cm_norm = np.nan_to_num(cm_norm)\n","    cm = np.round(cm_norm,2)\n","    print(cm)\n","\n","    # create figure\n","    fig = plt.figure()\n","    plt.clf()\n","    ax = fig.add_subplot(111)\n","    ax.set_aspect(1)\n","    ax.set_xlabel('Predicted label')\n","    ax.set_ylabel('True label')\n","    res = ax.imshow(cm, cmap=plt.cm.binary,\n","                    interpolation='nearest', vmin=0, vmax=1)\n","\n","    # add color bar\n","    plt.colorbar(res)\n","\n","    # annotate confusion entries\n","    width = len(cm)\n","    height = len(cm[0])\n","\n","    for x in xrange(width):\n","        for y in xrange(height):\n","            ax.annotate(str(cm[x][y]), xy=(y, x), horizontalalignment='center',\n","                        verticalalignment='center', color=getFontColor(cm[x][y]))\n","\n","    # add genres as ticks\n","    alphabet = mods \n","    plt.xticks(range(width), alphabet[:width], rotation=30)\n","    plt.yticks(range(height), alphabet[:height])\n","    return plt\n","\n","class MonitorCallback(tflearn.callbacks.Callback):\n","    def __init__(self, model):\n","        self.model = model\n","        self.accuracy = 0.0\n","\n","    def on_epoch_end(self, training_state):\n","        print(\"accuracy2:\", training_state.val_acc) \n","        if self.accuracy<training_state.val_acc:\n","           self.accuracy = training_state.val_acc \n","           print(\"Model saved:\", self.accuracy) \n","           self.model.save('lstm_apclaasify_newtf.tfl')\n","\n","\n","network = tflearn.input_data(shape=[None, maxlen, 2],name=\"inp\")\n","network = tflearn.lstm(network, 128, return_seq=True, dynamic=True, dropout=(1, 0.8))\n","#network = tf.transpose(tf.stack(network),[1,0,2])\n","network = tflearn.lstm(network, 128, dynamic=True, dropout=(0.8,1))\n","network = tflearn.fully_connected(network, len(mods), activation='softmax',name=\"out\")\n","network = tflearn.regression(network, optimizer='adam',\n","                 loss='categorical_crossentropy',\n","                 learning_rate=0.001)\n","model = tflearn.DNN(network,tensorboard_verbose=0)\n","\n","monitorCallback = MonitorCallback(model)\n","\n","Train = True \n","if Train:\n","    model.fit(X_train, Y_train, n_epoch=80, shuffle=True,show_metric=True, batch_size=400,validation_set=(X_test, Y_test), run_id='radio_lstm', callbacks=monitorCallback)\n","else:\n","    model.load('lstm_apclaasify_newtf.tfl')\n","\n","classes = mods\n","\n","acc={}\n","for snr in snrs:\n","    test_SNRs = map(lambda x: lbl[x][1], test_idx)\n","    test_X_i = X_test[np.where(np.array(test_SNRs)==snr)]\n","    test_Y_i = Y_test[np.where(np.array(test_SNRs)==snr)]    \n","\n","    # estimate classes\n","    test_Y_i_hat = np.array(model.predict(test_X_i))\n","    width = 4.1 \n","    height = width / 1.618\n","    plt.figure(figsize=(width, height))\n","    plt = getConfusionMatrixPlot(np.argmax(test_Y_i, 1), np.argmax(test_Y_i_hat, 1))\n","    plt.gcf().subplots_adjust(bottom=0.15)\n","    plt.savefig(\"./images/confmat_\"+str(snr)+\".pdf\")\n","    conf = np.zeros([len(classes),len(classes)])\n","    confnorm = np.zeros([len(classes),len(classes)])\n","    for i in range(0,test_X_i.shape[0]):\n","        j = list(test_Y_i[i,:]).index(1)\n","        k = int(np.argmax(test_Y_i_hat[i,:]))\n","        conf[j,k] = conf[j,k] + 1 \n","    for i in range(0,len(classes)):\n","        confnorm[i,:] = conf[i,:] / np.sum(conf[i,:])\n","    plt.figure()\n","    cor = np.sum(np.diag(conf))\n","    ncor = np.sum(conf) - cor \n","    print(\"Overall Accuracy: \", cor / (cor+ncor))\n","    acc[snr] = 1.0*cor/(cor+ncor)\n","print(acc)\n"],"execution_count":8,"outputs":[{"output_type":"error","ename":"UnicodeDecodeError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mUnicodeDecodeError\u001b[0m                        Traceback (most recent call last)","\u001b[0;32m<ipython-input-8-2e4f76956faa>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     68\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m \u001b[0mxtrain1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mxtest1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mytrain1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mytest1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgendata\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/drive/MyDrive/Colab Notebooks/Data/RML2016.10a_dict.pkl'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m128\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-8-2e4f76956faa>\u001b[0m in \u001b[0;36mgendata\u001b[0;34m(fp, nsamples)\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mgendata\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnsamples\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0;32mglobal\u001b[0m \u001b[0msnrs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmods\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlbl\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0mXd\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_path\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mfile_name\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m     \u001b[0msnrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmods\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mj\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0msorted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mXd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mUnicodeDecodeError\u001b[0m: 'ascii' codec can't decode byte 0xc1 in position 2: ordinal not in range(128)"]}]}]}