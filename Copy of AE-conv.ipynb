{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Copy of AE-conv.ipynb","provenance":[{"file_id":"1KpBeHwf6NshK6qXxAF-MO3FelmWns_qx","timestamp":1627236616428}],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"BAgdx8jze5CW"},"source":["## Mounting drive"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"9MLNSecLW45X","executionInfo":{"status":"ok","timestamp":1627234670257,"user_tz":420,"elapsed":137,"user":{"displayName":"Amadou Tall","photoUrl":"","userId":"06820629351691459518"}},"outputId":"48812ca9-0943-4d83-aa61-16a98242a03a"},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"PGmnOsEUfGQq"},"source":["## 1. Loading data"]},{"cell_type":"code","metadata":{"id":"Pr8yAx7NXVpS"},"source":["import pickle\n","import numpy as np\n","import random"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"QawPybbNXjDm","colab":{"base_uri":"https://localhost:8080/","height":215},"executionInfo":{"status":"error","timestamp":1627236476872,"user_tz":420,"elapsed":154,"user":{"displayName":"Amadou Tall","photoUrl":"","userId":"06820629351691459518"}},"outputId":"bcbe8772-e132-4846-b4fd-025c71470f38"},"source":["with open('/content/drive/MyDrive/Colab Notebooks/Data/gnu_data.pkl', 'rb') as file:\n","    Xd = pickle.load(file,encoding='latin1')\n","# open a file, where you stored the pickled data\n"],"execution_count":null,"outputs":[{"output_type":"error","ename":"FileNotFoundError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-8-145bc0d637c8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/drive/MyDrive/Colab Notebooks/Data/gnu_data.pkl'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mfile\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0mXd\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'latin1'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# open a file, where you stored the pickled data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/drive/MyDrive/Colab Notebooks/Data/gnu_data.pkl'"]}]},{"cell_type":"code","metadata":{"id":"GHIldZqOXkuu"},"source":["Xd['X']\n","Xd['lbl']\n","\n","X     = []\n","modul = []\n","snr   = []\n","\n","for i in range(len(Xd['X'])):\n","    x_ = Xd['X'][i]\n","    x_ = np.expand_dims(x_.transpose([1,0]),axis=2)\n","    X.append(x_)\n","    \n","    lbl = Xd['lbl'][i]\n","    modul.append(lbl[0])\n","    snr.append(int(lbl[1]))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"hCWTYfuMfJXg"},"source":["### 1.1. Train/Test Split"]},{"cell_type":"code","metadata":{"id":"__Y7wHsSYJjk"},"source":["train_test_split = 0.8\n","\n","random.seed(100)\n","random.shuffle(X)\n","\n","random.seed(100)\n","random.shuffle(modul)\n","\n","random.seed(100)\n","random.shuffle(snr)\n","\n","\n","X_train = np.array(X[:int(train_test_split*len(X))])\n","X_test  = np.array(X[int(train_test_split*len(X)):])\n","\n","modul_train = modul[:int(train_test_split*len(X))]\n","modul_test  = modul[int(train_test_split*len(X)):]\n","\n","snr_train = snr[:int(train_test_split*len(X))]\n","snr_test  = snr[int(train_test_split*len(X)):]"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"_u3G7DydfpbV"},"source":["### 1.2. Generating One-hot encoded"]},{"cell_type":"code","metadata":{"id":"k6xvyHtGfpA6"},"source":["mods = list(set(modul_train))\n","print(len(mods))\n","\n","def to_onehot(yy):\n","    yy1 = np.zeros([1, len(mods)])\n","    yy1[0,mods.index(yy)] = 1\n","    return yy1\n","\n","Y_train = np.zeros([len(modul_train),len(mods)])\n","Y_test = np.zeros([len(modul_test),len(mods)])\n","\n","for i in range(len(modul_train)):\n","  Y_train[i,:] = to_onehot(modul_train[i])\n","\n","for i in range(len(modul_test)):\n","  Y_test[i,:] = to_onehot(modul_test[i]) "],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"TGQ95vjMfPfl"},"source":["## 2. Train Deep Neural Networks"]},{"cell_type":"markdown","metadata":{"id":"-f6J_-kufXFO"},"source":["### 2.1. Train Auto-Encoder (AE)"]},{"cell_type":"code","metadata":{"id":"A6ou-bCcYKGC"},"source":["import keras\n","\n","# This is our input image\n","input_data     = keras.Input(shape=(128,2,1,))\n","\n","x = keras.layers.Conv2D(8, (3, 3), activation='tanh', padding='same')(input_data)\n","x = keras.layers.MaxPooling2D((2, 2), padding='same')(x)\n","x = keras.layers.Conv2D(16, (3, 3), activation='tanh', padding='same')(x)\n","x = keras.layers.MaxPooling2D((2, 2), padding='same')(x)\n","x = keras.layers.Conv2D(32, (3, 3), activation='tanh', padding='same')(x)\n","encoded = keras.layers.MaxPooling2D((2, 2), padding='same', name='encoding')(x)\n","\n","x = keras.layers.Conv2D(32, (3, 3), activation='tanh', padding='same')(encoded)\n","x = keras.layers.UpSampling2D((2, 2))(x)\n","x = keras.layers.Conv2D(16, (3, 3), activation='tanh', padding='same')(x)\n","x = keras.layers.UpSampling2D((2, 1))(x)\n","x = keras.layers.Conv2D(8, (3, 3), activation='tanh', padding='same')(x)\n","x = keras.layers.UpSampling2D((2, 1))(x)\n","decoded = keras.layers.Conv2D(1, (3, 3), activation='tanh', padding='same')(x)\n","\n","# This model maps an input to its reconstruction\n","autoencoder = keras.Model(input_data, decoded)\n","autoencoder.compile(loss='mse', optimizer='adam')\n","autoencoder.summary()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"CVa0OBLfYevQ"},"source":["# Set up some params \n","nb_epoch = 1000     # number of epochs to train on\n","batch_size = 32  # training batch size\n","\n","filepath = '/content/drive/My Drive/upwork/amadou/AE.h5'\n","autoencoder.fit(X_train,\n","    X_train,\n","    batch_size=batch_size,\n","    epochs=nb_epoch,\n","    verbose=1,\n","    validation_data=(X_test,X_test),\n","    callbacks = [\n","        keras.callbacks.ModelCheckpoint(filepath, monitor='val_loss', verbose=0, save_best_only=True, mode='auto'),\n","        keras.callbacks.EarlyStopping(monitor='val_loss', patience=5, verbose=0, mode='auto')]\n","    )\n","# we re-load the best weights once training is finished\n","autoencoder.load_weights(filepath)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"GtskO1KEfhpi"},"source":["### 2.2. Define Encoder model (trained)"]},{"cell_type":"code","metadata":{"id":"ve5JXewzhh-2"},"source":["encoder_model = keras.Model(inputs=autoencoder.input,\n","                                 outputs=autoencoder.get_layer('encoding').output)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"gHWRIRjygBL2"},"source":["### 2.3. Calculate Encoded data (train & test) using trained Encoder Model"]},{"cell_type":"code","metadata":{"id":"7WsI-sTJjvKg"},"source":["encoded_train = encoder_model.predict(X_train, verbose=1)\n","encoded_test  = encoder_model.predict(X_test, verbose=1)\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"HGBAuXe5crr8"},"source":["encoded_train = encoded_train.reshape(encoded_train.shape[0],-1)\n","encoded_test  = encoded_test.reshape(encoded_test.shape[0],-1)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"6_hysDW8daup"},"source":["encoded_train.shape"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Iea9uP6WgPg7"},"source":["### 2.4. Train MLP Classifier"]},{"cell_type":"code","metadata":{"id":"O-alHGxUkoPQ"},"source":["model = keras.models.Sequential()\n","model.add(keras.layers.Dense(256, activation='relu', name=\"dense1\", input_shape=(512,)))\n","model.add(keras.layers.Dropout(0.1))\n","model.add(keras.layers.Dense(256, activation='relu', name=\"dense2\"))\n","model.add(keras.layers.Dropout(0.1))\n","model.add(keras.layers.Dense( 11, name=\"output\" ))\n","model.add(keras.layers.Activation('softmax'))\n","model.compile(loss='categorical_crossentropy', optimizer='adam',metrics='acc')\n","model.summary()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"A5DvLB0jnQkM"},"source":["filepath = '/content/drive/My Drive/upwork/amadou/AE_MLP.h5'\n","\n","model.fit(encoded_train,\n","    Y_train,\n","    batch_size=batch_size,\n","    epochs=nb_epoch,\n","    verbose=1,\n","    validation_data=(encoded_test,Y_test),\n","    callbacks = [\n","        keras.callbacks.ModelCheckpoint(filepath, monitor='val_loss', verbose=0, save_best_only=True, mode='auto'),\n","        keras.callbacks.EarlyStopping(monitor='val_loss', patience=5, verbose=0, mode='auto')]\n","    )\n","# we re-load the best weights once training is finished\n","model.load_weights(filepath)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"E_tuOktugWeZ"},"source":["## 3. Evaluating the trained classifier"]},{"cell_type":"code","metadata":{"id":"R8mMZwWLLU-6"},"source":["snrs= list(set(snr))\n","snrs.sort()\n","\n","import matplotlib.pyplot as plt\n","def plot_confusion_matrix(cm, title='Confusion matrix', cmap=plt.cm.Blues, labels=[]):\n","    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n","    plt.title(title)\n","    plt.colorbar()\n","    tick_marks = np.arange(len(labels))\n","    plt.xticks(tick_marks, labels, rotation=45)\n","    plt.yticks(tick_marks, labels)\n","    plt.tight_layout()\n","    plt.ylabel('True label')\n","    plt.xlabel('Predicted label')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"NoBOcX-EoJTT"},"source":["\n","# Plot confusion matrix\n","acc = {}\n","for snr_value in snrs:\n","\n","    # extract classes @ SNR\n","    test_X_i = X_test[np.where(np.array(snr_test)==snr_value)]\n","    test_Y_i = Y_test[np.where(np.array(snr_test)==snr_value)]    \n","\n","    # estimate classes\n","    test_encoded = encoder_model.predict(test_X_i)\n","    test_encoded = test_encoded.reshape(test_encoded.shape[0],-1)\n","    test_Y_i_hat = model.predict(test_encoded)\n","    conf = np.zeros([len(mods),len(mods)])\n","    confnorm = np.zeros([len(mods),len(mods)])\n","    for i in range(0,test_X_i.shape[0]):\n","        j = list(test_Y_i[i,:]).index(1)\n","        k = int(np.argmax(test_Y_i_hat[i,:]))\n","        conf[j,k] = conf[j,k] + 1\n","    for i in range(0,len(mods)):\n","        confnorm[i,:] = conf[i,:] / np.sum(conf[i,:])\n","    plt.figure()\n","    plot_confusion_matrix(confnorm, labels=mods, title=\"AE Confusion Matrix (SNR=%d)\"%(int(snr_value)))\n","    \n","    cor = np.sum(np.diag(conf))\n","    ncor = np.sum(conf) - cor\n","    print (\"Overall Accuracy: \", cor / (cor+ncor))\n","    acc[snr_value] = 1.0*cor/(cor+ncor)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"VPOhXAKaJ8yk"},"source":["acc_ = [acc[snr_value] for snr_value in snrs]\n","\n","# Plot accuracy curve\n","plt.plot(snrs, acc_)\n","plt.xlabel(\"Signal to Noise Ratio\")\n","plt.ylabel(\"Classification Accuracy\")\n","plt.title(\"AE Classification Accuracy on RadioML 2016.10 Alpha\")"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"0M2YsJ5Yh9vp"},"source":["## Display data"]},{"cell_type":"code","metadata":{"id":"YezYIaVBhJwT"},"source":["import pandas as pd\n","print('real')\n","pd.DataFrame(X_train[:,:,0,0]).head()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"vTQ8rGwohUf3"},"source":["print('imaginary')\n","pd.DataFrame(X_train[:,:,1,0]).head()"],"execution_count":null,"outputs":[]}]}